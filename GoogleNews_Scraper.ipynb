{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogleNews Scrapper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwynw2Ag1rYG39RLHKt2Vt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasugamdha/random-colab-notebooks/blob/main/GoogleNews_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtio-jONfQ-0"
      },
      "source": [
        "# Web-scrapping news using Google News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Ey6GVNylXC",
        "outputId": "0a108c93-2761-4c47-9c22-fba92644eaba"
      },
      "source": [
        "!pip install GoogleNews\n",
        "!pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GoogleNews\n",
            "  Downloading https://files.pythonhosted.org/packages/f4/ef/058cd7c1991e9b6d9aa2d7d286a2655e17b436e8e3c48ccdd0b73b648cde/GoogleNews-1.5.5-py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from GoogleNews) (4.6.3)\n",
            "Collecting dateparser\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/c4/b5ddc3eeac974d85055d88c1e6b62cc492fc1a93dbe3b66a45a756a7b807/dateparser-1.0.0-py2.py3-none-any.whl (279kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from GoogleNews) (2.8.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser->GoogleNews) (2018.9)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser->GoogleNews) (1.5.1)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser->GoogleNews) (2019.12.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->GoogleNews) (1.15.0)\n",
            "Installing collected packages: dateparser, GoogleNews\n",
            "Successfully installed GoogleNews-1.5.5 dateparser-1.0.0\n",
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.0.0)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.23.0)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Collecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/21/faf1bac028662cc8adb2b5ef7a6f3999a765baa2835331df365289b0ca56/feedparser-6.0.2-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/62/b6acd3129c5615b9860e670df07fd55b76175b63e6b7f68282c7cad38e9e/tldextract-3.1.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.8MB/s \n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n",
            "Collecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.1)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Collecting sgmllib3k\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp37-none-any.whl size=13538 sha256=490a1d8f3478dbb0785dd4c718957f50924764051bb5f98618298517d1b0240f\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp37-none-any.whl size=3358 sha256=e10363fd365fa3bb945173949df29444b47ebd1fa83c79d7b8c424720439cb2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp37-none-any.whl size=7398406 sha256=4d21249549b34a2209409e27397daed5c0147a9a23aaf072f257134354918f55\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp37-none-any.whl size=6067 sha256=d5125722a2118ec1dd1f69f376608cf9d014a0810bce76b498c9e2540bcb8f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, feedparser, requests-file, tldextract, feedfinder2, jieba3k, cssselect, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.2 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTJxtRuAydDt"
      },
      "source": [
        "from GoogleNews import GoogleNews\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m20W6CGCE1lr"
      },
      "source": [
        "'''Config will allow us to access the specified url for which we are not authorized.  \n",
        "So, sometimes we may get 403 client error while parsing the link to download the article.'''\n",
        "\n",
        "from newspaper import Config\n",
        "user_agent = 'Chrome/50.0.2661.102'\n",
        "config = Config()\n",
        "config.browser_user_agent = user_agent\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "bO1-qZjsyfMi",
        "outputId": "0fd74264-3382-41ac-9505-6a454a204b00"
      },
      "source": [
        "#@title Extracting results from GoogleNews\n",
        "googlenews=GoogleNews(start='11/01/2020',end='12/31/2020')  # mm/dd/yyyy\n",
        "googlenews.search('Elon Musk')\n",
        "n=5 # number of pages \n",
        "for i in range(2,n):\n",
        "    googlenews.get_page(i)\n",
        "    result=googlenews.results(sort=True)\n",
        "    df=pd.DataFrame(result)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>media</th>\n",
              "      <th>date</th>\n",
              "      <th>datetime</th>\n",
              "      <th>desc</th>\n",
              "      <th>link</th>\n",
              "      <th>img</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Twitter debates with Elon Musk, death threats ...</td>\n",
              "      <td>masslive.com</td>\n",
              "      <td>Dec 31, 2020</td>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>Twitter debates with Elon Musk, death threats ...</td>\n",
              "      <td>https://www.masslive.com/coronavirus/2020/12/t...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Elon Musk says SpaceX will attempt to recover ...</td>\n",
              "      <td>TechCrunch</td>\n",
              "      <td>Dec 30, 2020</td>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>SpaceX will try a significantly different appr...</td>\n",
              "      <td>https://techcrunch.com/2020/12/30/elon-musk-sa...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Elon Musk: Teslas delivered in final days of 2...</td>\n",
              "      <td>Business Insider</td>\n",
              "      <td>Dec 29, 2020</td>\n",
              "      <td>2020-12-29</td>\n",
              "      <td>Elon Musk said in a tweet Tuesday that Tesla v...</td>\n",
              "      <td>https://www.businessinsider.com/elon-musk-tesl...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tesla Stock Jumps After Elon Musk Says It’s ‘I...</td>\n",
              "      <td>Barron's</td>\n",
              "      <td>Dec 28, 2020</td>\n",
              "      <td>2020-12-28</td>\n",
              "      <td>No matter what happens in 2021, one sure thing...</td>\n",
              "      <td>https://www.barrons.com/articles/tesla-stock-j...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Elon Musk says it's now 'impossible' to take T...</td>\n",
              "      <td>Business Insider</td>\n",
              "      <td>Dec 26, 2020</td>\n",
              "      <td>2020-12-26</td>\n",
              "      <td>The term \"going private\" refers to converting ...</td>\n",
              "      <td>https://www.businessinsider.com/elon-musk-tesl...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ...                                                img\n",
              "0  Twitter debates with Elon Musk, death threats ...  ...  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...\n",
              "1  Elon Musk says SpaceX will attempt to recover ...  ...  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...\n",
              "2  Elon Musk: Teslas delivered in final days of 2...  ...  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...\n",
              "3  Tesla Stock Jumps After Elon Musk Says It’s ‘I...  ...  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...\n",
              "4  Elon Musk says it's now 'impossible' to take T...  ...  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4XqlIR91LiZ",
        "outputId": "cadb2bc5-30c2-4acc-aa9f-ddb563444725"
      },
      "source": [
        "#@title For extracting full articles from links\n",
        "from newspaper import Article\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "news=[]\n",
        "for ind in df.index:\n",
        "    dict={}\n",
        "\n",
        "    article = Article(df['link'][ind],config=config)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    article.nlp()\n",
        "\n",
        "    dict['Date']=df['date'][ind]\n",
        "    dict['Media']=df['media'][ind]\n",
        "    dict['Title']=article.title\n",
        "    dict['Link']=df['link'][ind]\n",
        "    dict['Article']=article.text\n",
        "    dict['Summary']=article.summary\n",
        "\n",
        "    news.append(dict)\n",
        "news_df=pd.DataFrame(news)\n",
        "news_df.to_csv(\"articles.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "180TT9vXkkax"
      },
      "source": [
        "# If you are facing any timeout issues\n",
        "# Check this out and modify parameters according to your needs: https://newspaper.readthedocs.io/en/latest/user_guide/advanced.html#parameters-and-configurations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsVRjQxAIqTQ"
      },
      "source": [
        "# Reference: https://medium.com/analytics-vidhya/googlenews-api-live-news-from-google-news-using-python-b50272f0a8f0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}